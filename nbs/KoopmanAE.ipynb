{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d56b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from magtense.utils import plot_M_thin_film\n",
    "\n",
    "from koopmag.database import create_db_mp\n",
    "from koopmag.utils import plot_dynamics\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def add_colorbar(im, fig, ax) -> None:\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946b0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of database:\n",
      "grid_size: [5.00e-07 1.25e-07 3.00e-09]\n",
      "h_ext_angle: [  0 360]\n",
      "h_ext_norm: [ 0 50]\n",
      "res: [36  9  1]\n",
      "seed: 0\n",
      "t_per_step: 1e-11\n",
      "t_steps: 200\n",
      "\n",
      "Data in the database:\n",
      "field: (20, 3)\n",
      "sequence: (20, 200, 36, 9, 3)\n"
     ]
    }
   ],
   "source": [
    "datapath = Path().cwd().parent / \"data\"\n",
    "db = h5py.File(datapath / \"20_200_36_9.h5\", \"r\")\n",
    "\n",
    "print(\"Attributes of database:\")\n",
    "for key in db.attrs:\n",
    "    print(f\"{key}: {db.attrs[key]}\")\n",
    "\n",
    "print(\"\\nData in the database:\")\n",
    "for key in db:\n",
    "    print(f\"{key}: {db[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ad32f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated dimension: from (36, 9, 3) to (972,)\n",
      "Xs shape: (20, 199, 972) (n_seq, n_tsteps, n_x * n_y * 3)\n",
      "Ys shape: (20, 199, 972) (n_seq, n_tsteps, n_x * n_y * 3)\n"
     ]
    }
   ],
   "source": [
    "Hs = np.array(db[\"field\"])\n",
    "\n",
    "data = np.array(db[\"sequence\"])\n",
    "\n",
    "n_seq, n_tsteps, data_dim = *data.shape[:2], data.shape[2:]\n",
    "\n",
    "data = data.reshape((n_seq, n_tsteps, -1))\n",
    "Xs = data[:, :-1, :]\n",
    "Ys = data[:,  1:, :]\n",
    "\n",
    "print(f\"Concatenated dimension: from {data_dim} to ({np.prod(data_dim)},)\")\n",
    "\n",
    "print(f\"Xs shape: {Xs.shape} (n_seq, n_tsteps, n_x * n_y * 3)\")\n",
    "print(f\"Ys shape: {Xs.shape} (n_seq, n_tsteps, n_x * n_y * 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5afcc56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 199, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtorch = torch.tensor(Xs, dtype=torch.float32)\n",
    "Ytorch = torch.tensor(Ys, dtype=torch.float32)\n",
    "\n",
    "Htorch = torch.stack(\n",
    "    [\n",
    "        torch.stack(\n",
    "            [torch.tensor(Hs[i], dtype=torch.float32) for _ in range(n_tsteps - 1)]\n",
    "        )\n",
    "        for i in range(n_seq)\n",
    "    ]\n",
    ")\n",
    "\n",
    "Htorch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b1e33",
   "metadata": {},
   "source": [
    "### Koopman Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ecbd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCEncoder(nn.Module):\n",
    "    '''\n",
    "    Encoder block for Autoencoder with fully connected layers.\n",
    "    takes as input a list of number of nodes per layer\n",
    "    and an activation function\n",
    "    '''\n",
    "    def __init__(self, dim_list, act_fn=nn.Tanh) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        module_list = []\n",
    "        for i in range(len(dim_list)-1):\n",
    "            module_list.append(nn.Linear(dim_list[i], dim_list[i+1]))\n",
    "            if i != len(dim_list)-2:\n",
    "                module_list.append(act_fn())\n",
    "\n",
    "        self.fc = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class FCDecoder(nn.Module):\n",
    "    '''\n",
    "    Decoder block for Autoencoder with fully connected layers.\n",
    "    takes as input a list of number of nodes per layer\n",
    "    and an activation function\n",
    "    '''\n",
    "    def __init__(self, dim_list, act_fn=nn.Tanh) -> None:\n",
    "        super().__init__()\n",
    "        module_list = []\n",
    "        for i in range(len(dim_list)-1, 0, -1):\n",
    "            module_list.append(nn.Linear(dim_list[i], dim_list[i-1]))\n",
    "            if i != 1:\n",
    "                module_list.append(act_fn())\n",
    "\n",
    "        self.fc = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class DeepKoopman(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_list, act_fn=nn.Tanh) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = FCEncoder(dim_list, act_fn)\n",
    "        self.decoder = FCDecoder(dim_list, act_fn)\n",
    "\n",
    "        self.B = nn.Parameter(torch.empty(3, dim_list[-1])) # shape (n_magnetization, d)\n",
    "        nn.init.xavier_uniform_(self.B, gain=0.01)          # initialise B matrix values\n",
    "\n",
    "    def compute_linear_operator(self, Xtilde, Ytilde) -> torch.Tensor:\n",
    "\n",
    "        self.A = torch.linalg.pinv(Xtilde) @ Ytilde\n",
    "        return self.A\n",
    "\n",
    "    def forward(self, X, Y, U=None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        params:\n",
    "        X: input data (n x m)\n",
    "        Y: target data (n x m)\n",
    "        U: external effect (n x 3)\n",
    "        '''\n",
    "        T = X.shape[0]\n",
    "        T_half = T // 2\n",
    "        Xtilde = self.encoder(X)    # encode X: (n x m)  -> Xtilde: (n x d)\n",
    "        Ytilde = self.encoder(Y)    # encode Y: (n x m)  -> Ytilde: (n x d)\n",
    "\n",
    "        ext_effect = U[:T_half, :] @ self.B if U is not None else 0 # shape (n//2 x d)\n",
    "\n",
    "        # compute linear operator according to \n",
    "        # A = (Ytilde - B @ U) @ Xtilde^+\n",
    "        A = self.compute_linear_operator(\n",
    "            Xtilde[:T_half,:], Ytilde[:T_half,:] - ext_effect\n",
    "            )\n",
    "\n",
    "        Ytilde_pred_list = [Xtilde[0] @ A]\n",
    "        for t in range(1, T):\n",
    "            next_pred = Ytilde_pred_list[t-1] @ A\n",
    "            if U is not None:\n",
    "                next_pred += U[t,:] @ self.B\n",
    "            Ytilde_pred_list.append(next_pred)\n",
    "        \n",
    "        Ytilde_pred = torch.stack(Ytilde_pred_list, dim=0)\n",
    "        \n",
    "        Xhat = self.decoder(Xtilde)\n",
    "        Yhat = self.decoder(Ytilde_pred)\n",
    "\n",
    "        return Xhat, Yhat\n",
    "    \n",
    "    \n",
    "    def predict(self, X, T, U=None) -> torch.Tensor:\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.unsqueeze(0)  # make it (1, input_dim)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            Xtilde0 = self.encoder(X)    # encode X: (n x m)  -> Xtilde: (n x d)\n",
    "            Ytilde_pred = torch.zeros((T, Xtilde0.shape[1])).to(Xtilde0.device)\n",
    "            Ytilde_pred[0] = Xtilde0 @ self.A \n",
    "            if U is not None:\n",
    "                Ytilde_pred[0] += U[0,:] @ self.B\n",
    "            for t in range(1, T):\n",
    "                Ytilde_pred[t] = Ytilde_pred[t-1] @ self.A\n",
    "                if U is not None:\n",
    "                    Ytilde_pred[t] += U[t,:] @ self.B\n",
    "            \n",
    "            Yhat = self.decoder(Ytilde_pred)\n",
    "        return Yhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koopmag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
